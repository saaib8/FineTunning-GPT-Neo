{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44bea0f0-b377-45d3-8480-791f2290c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0854a4-fede-4ea4-97a3-14cafcd106e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train[:1000]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fcd4280-a7ff-45a9-81db-c2b2decb9714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380bcafeb48c41c18ea6d889e00dfd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_instruction(example):\n",
    "    instruction = f\"### Instruction:\\n{example['instruction']}\\n\"\n",
    "    input_text = f\"### Input:\\n{example['input']}\\n\" if example['input'] else \"\"\n",
    "    response = f\"### Response:\\n{example['output']}\"\n",
    "    return {\"text\": instruction + input_text + response}\n",
    "\n",
    "dataset = dataset.map(format_instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a58ba8a-195d-4f57-97bf-1cb91444d5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Give three tips for staying healthy.',\n",
       " 'input': '',\n",
       " 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.',\n",
       " 'text': '### Instruction:\\nGive three tips for staying healthy.\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4170be08-2e3e-4021-a06b-935000d5d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.53.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a781eef-9fc0-4ff7-9619-3e22f852ca2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/43/3nlhlsy152l07ynqz_fk1gsh0000gn/T/ipykernel_46901/537854140.py\", line 1, in <module>\n",
      "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/__init__.py\", line 27, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/__init__.py\", line 24, in <module>\n",
      "    from .args_doc import (\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/args_doc.py\", line 30, in <module>\n",
      "    from .generic import ModelOutput\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py\", line 46, in <module>\n",
      "    import torch  # noqa: F401\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597eecc6-2a11-4da4-955c-28062a1e88c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1812430c-838c-4286-be37-13ff8dea848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca69b77-0833-441e-8c35-b7080a826e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca93e599ce5473b865c2f4f09737d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bed314c-06bf-41b4-863b-035b6a449d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt-neo-alpaca-10k\",\n",
    "    per_device_train_batch_size=2,     # Keep this small for memory\n",
    "    gradient_accumulation_steps=4,     # Accumulate to simulate a batch of 8\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=50,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=1,\n",
    "    fp16=False,  # Not for MPS (Mac), only use on CUDA\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "878165af-c1e3-4cb5-af78-dae8a1c799ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 10:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.233800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.935700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.781200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.784100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=1.9680098571777345, metrics={'train_runtime': 608.7171, 'train_samples_per_second': 3.286, 'train_steps_per_second': 0.411, 'total_flos': 261207097344000.0, 'train_loss': 1.9680098571777345, 'epoch': 2.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29c32628-54d0-49e8-9973-5fb74a8cb63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt-neo-finetuned/tokenizer_config.json',\n",
       " './gpt-neo-finetuned/special_tokens_map.json',\n",
       " './gpt-neo-finetuned/vocab.json',\n",
       " './gpt-neo-finetuned/merges.txt',\n",
       " './gpt-neo-finetuned/added_tokens.json',\n",
       " './gpt-neo-finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./gpt-neo-finetuned\")\n",
    "tokenizer.save_pretrained(\"./gpt-neo-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3662586f-fca4-40ae-91e4-976a944378e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./gpt-neo-finetuned\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./gpt-neo-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80709631-441b-4451-b423-1af60fd17d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Give tips for healthy skin.\n",
      "### Response:\n",
      "1. Protect your skin from light, heat, and other harmful substances.\n",
      "2. Make sure your skin is hydrated with hydrated oils and sun protection.\n",
      "3. Have a sun-drenched bath.\n",
      "4. Have a good and warm bath.\n",
      "5. Use moisturizer and oil-based products.\n",
      "6. Get a good skin routine.\n",
      "7. Make sure to wash your hands and\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"### Instruction:\n",
    "Give tips for healthy skin .\n",
    "### Response:\"\"\"\n",
    "\n",
    "# Move tokenizer input to CPU\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cpu\")\n",
    "\n",
    "# Move model to CPU\n",
    "model.to(\"cpu\")\n",
    "\n",
    "# Generate output\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    max_length=100,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "# Decode and print result\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "412eeece-1868-4f9b-8086-1457fdf2fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer (same for both)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "\n",
    "# Load base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-125M\").to(\"cpu\")\n",
    "\n",
    "# Load fine-tuned model\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(\"./gpt-neo-finetuned\").to(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ac30d38-807f-47bd-bdc6-a2de746dfbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, prompt, tokenizer, max_length=100):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cpu\")\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=max_length,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, \"\").strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd699cd3-d485-40e3-9f20-61fc41275f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"### Instruction:\\nGive tips to stay healthy.\\n### Response:\",\n",
    "    \"### Instruction:\\nPrepare me a plan to mountains\\n### Response:\",\n",
    "    \"### Instruction:\\nWhat are the benefits of drinking water?\\n### Response:\",\n",
    "    \"### Instruction:\\nSuggest ways to reduce screen time.\\n### Response:\",\n",
    "    \"### Instruction:\\nWhat should I do if I feel anxious?\\n### Response:\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5e63dd7-8e59-41fa-862d-b01b02a49702",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    base_output = generate_response(base_model, prompt, tokenizer)\n",
    "    finetuned_output = generate_response(finetuned_model, prompt, tokenizer)\n",
    "    data.append([prompt, base_output, finetuned_output])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Prompt\", \"Base Model\", \"Fine-Tuned Model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04abdec8-7616-46ba-9a0a-e87122e02a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_full_dataframe(df):\n",
    "    styles = [\n",
    "        dict(selector=\"td\", props=[(\"white-space\", \"pre-wrap\")]),\n",
    "        dict(selector=\"th\", props=[(\"white-space\", \"pre-wrap\")]),\n",
    "    ]\n",
    "    html = df.style.set_table_styles(styles).to_html()\n",
    "    display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e91e573-6a9b-4c19-81fa-ecd6978db43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_81f90 td {\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_81f90 th {\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_81f90\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_81f90_level0_col0\" class=\"col_heading level0 col0\" >Prompt</th>\n",
       "      <th id=\"T_81f90_level0_col1\" class=\"col_heading level0 col1\" >Base Model</th>\n",
       "      <th id=\"T_81f90_level0_col2\" class=\"col_heading level0 col2\" >Fine-Tuned Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_81f90_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_81f90_row0_col0\" class=\"data row0 col0\" >### Instruction:\n",
       "Give tips to stay healthy.\n",
       "### Response:</td>\n",
       "      <td id=\"T_81f90_row0_col1\" class=\"data row0 col1\" >Don't give up!\n",
       "\n",
       "## Chapter 5  \n",
       "What Happens When You're Not in the Heart of the Universe?\n",
       "\n",
       "### What Happens When You're in the Heart of the Universe?\n",
       "\n",
       "In the last chapter, we've discussed some of the most important things about the universe and how we live it. We've also covered some of the ways in which we have to be careful about how</td>\n",
       "      <td id=\"T_81f90_row0_col2\" class=\"data row0 col2\" >1. Eat lots of fruits and vegetables.\n",
       "2. Try to stay hydrated and stay hydrated while exercising.\n",
       "3. Eat enough to keep you healthy.\n",
       "4. Exercise regularly.\n",
       "5. Eat lots of healthy food.\n",
       "6. Take a good nap.\n",
       "7. Have a good meal.\n",
       "8. Drink plenty of water.\n",
       "9. Try to stay hydrated and hydrate while</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81f90_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_81f90_row1_col0\" class=\"data row1 col0\" >### Instruction:\n",
       "Prepare me a plan to mountains\n",
       "### Response:</td>\n",
       "      <td id=\"T_81f90_row1_col1\" class=\"data row1 col1\" >Thank you for your reply.\n",
       "\n",
       "### Question:\n",
       "What's the purpose of the instruction?\n",
       "\n",
       "### Response:\n",
       "I know that the instructions are to get a mountain from a specific place.\n",
       "\n",
       "### Question:\n",
       "What's the purpose of the instruction?\n",
       "\n",
       "### Response:\n",
       "I know that the instructions are to get a mountain from a specific place.\n",
       "\n",
       "### Question:\n",
       "What's</td>\n",
       "      <td id=\"T_81f90_row1_col2\" class=\"data row1 col2\" >1. Write a plan for the mountains.\n",
       "2. Plan out the terrain.\n",
       "3. Take a trip to the top of the mountain.\n",
       "4. Go to the summit of the mountain.\n",
       "5. Follow a trail to the summit.\n",
       "6. Take a short hike to the summit.\n",
       "7. Go back to your car.\n",
       "8. Return to the car.\n",
       "9. Take a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81f90_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_81f90_row2_col0\" class=\"data row2 col0\" >### Instruction:\n",
       "What are the benefits of drinking water?\n",
       "### Response:</td>\n",
       "      <td id=\"T_81f90_row2_col1\" class=\"data row2 col1\" >Thank you for your answer.  It is quite a bit easier to find a good\n",
       "place to drink water in the UK than in the US.  I would prefer that you\n",
       "do so.  I don't think you have to be a water purifier, but I would advise\n",
       "that you do so.\n",
       "\n",
       "------\n",
       "dabren\n",
       "There's a couple of things I've noticed about the</td>\n",
       "      <td id=\"T_81f90_row2_col2\" class=\"data row2 col2\" >Water is essential to life. It is a source of nutrients and is essential for the growth and development of plants. It also helps to regulate body temperature and reduce blood pressure. It also helps to control the blood pressure, which can lead to a variety of health issues. Drinking water can also help to prevent diseases such as diabetes and stroke.\n",
       "### Response:\n",
       "Water can also help to reduce the risk of diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81f90_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_81f90_row3_col0\" class=\"data row3 col0\" >### Instruction:\n",
       "Suggest ways to reduce screen time.\n",
       "### Response:</td>\n",
       "      <td id=\"T_81f90_row3_col1\" class=\"data row3 col1\" >The following are the responses from the current page.</td>\n",
       "      <td id=\"T_81f90_row3_col2\" class=\"data row3 col2\" >- Implement a short text-to-speech system that utilizes a computer to monitor and analyze text.\n",
       "- Implement a short audio-to-visual system that utilizes a microphone to record audio.\n",
       "- Implement a short video-to-speech system that utilizes a voice recognition system to identify speech.\n",
       "- Implement a short text-to-speech system that utilizes a voice recognition system to identify text.\n",
       "- Implement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81f90_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_81f90_row4_col0\" class=\"data row4 col0\" >### Instruction:\n",
       "What should I do if I feel anxious?\n",
       "### Response:</td>\n",
       "      <td id=\"T_81f90_row4_col1\" class=\"data row4 col1\" >Thank you for your answers and I will try to answer some more questions.\n",
       "\n",
       "### Suggested Answer:\n",
       "This is a response from a member of [ Lantern Forums] for which you have\n",
       "the option to reach the original consensus.\n",
       "\n",
       "ulture\n",
       "\n",
       "Follow [ Lantern Forums FAQ | FAQ |rish tocsis |rish tocsis.tumblr.com] on [Gizmodo |</td>\n",
       "      <td id=\"T_81f90_row4_col2\" class=\"data row4 col2\" >1. Take a deep breath and focus on your goals.\n",
       "2. Write a book or a blog post.\n",
       "3. Get to know your audience and your products.\n",
       "4. Create an online calendar to keep track of your favorite topics.\n",
       "5. Write a blog post or blog post about your product.\n",
       "6. Write a blog post about your customer service experience.\n",
       "7. Send a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_full_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8b73c-1971-46d2-b633-f0c032d5984e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
